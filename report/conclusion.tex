\section{结论}
\label{sec:conclusion}

本次Kaggle比赛，我们通过精心调试Xgboost模型，使用很基础的特征就取得了前4\%的成绩。同时，我们通过学习Kaggle论坛上的脚本，对数据进行了可视化处理和观察分析。我们在构造特征时从多个角度进行了尝试。实验的过程中，我们发现构造的特征对于预测只有负面效果。我们针对这一现象进行了进一步实验，并做出了两种解释：构造特征时引入了对于预测目标的提示导致在训练集上过拟合；选用的模型不能很好地利用特征中的信息。

通过本次参加Kaggle比赛的经历，我们学习到了很多数据挖掘的经验。在面对实际的数据挖掘问题的时候，首先要多尝试不同的模型，来得出哪些模型比较适合这个问题。另外，不能闭门造车地纯做特征工程，因为无效的特征不仅会降低最终模型
的准确率，而且会增加模型的训练时间，因此增加特征值之后需要用模型对其进行检测，摒弃其中无效的部分；也不能纯凭自己的想法添加特征，应当结合对数据的分析；还要考虑当前使用的模型的表达能力是否足够利用这些特征。
另外，在模型调参的过程中，要去思考模型的特性，贴合实际问题去调整参数，如果训练速度较快，可以使用自动的调参工具（Grid Search）来进行参数的选择。
最后就是要相信测试集上交叉检验的结果，当出现提交结果与本地分折测试结果相差较大的时候，通常是自己在某些方面犯了错误，应当将其找出并修复。